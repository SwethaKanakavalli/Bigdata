# -*- coding: utf-8 -*-
"""Swetha_LDA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Da-gGCYZscaArtLRcWc_cazD6ZWNbtXd
"""

#Importing required libraries
import numpy as np
import pandas as pd

df=pd.read_csv('ctg_data1.csv')
df

df.dtypes

df.isna().sum()

df.dropna()

df.isna().sum()

Features=df.drop('NSP', axis=1)
Label=df['NSP']

Features.shape

Features_T=Features.T
#Features_T.columns= Features_T.iloc[0]
#Features_T.columns

height, width = Features.shape
unique_classes = np.unique(Label)
unique_classes

num_classes = len(unique_classes)

scatter_train = np.cov(Features_T)*(height - 1)
scatter_within = 0

for i in range(num_classes):
  class_items = np.flatnonzero(Label == unique_classes[i])
  scatter_within = scatter_within + np.cov(Features_T[class_items]) * (len(class_items)-1)

scatter_between = scatter_train - scatter_within

#Calculating Eigenvalues and Eigenvectors of the covariance matrix

eigen_values, eigen_vectors = np.linalg.eigh(np.linalg.pinv(scatter_within).dot(scatter_between))
        #print(eig_vectors.shape)
        #pc = Features.dot(eig_vectors[:,::-1][:,:self.n_components])

#sort the eigenvalues in descending order
sorted_index = np.argsort(eigen_values)[::-1]
 
sorted_eigenvalue = eigen_values[sorted_index]
#similarly sort the eigenvectors 
sorted_eigenvectors = eigen_vectors[:,sorted_index]
sorted_eigenvectors

# select the first n eigenvectors, n is desired dimension
# of our final reduced data.
 
n_components = 30 #you can select any number of components.
eigenvector_subset = sorted_eigenvectors[:,0:n_components]
eigenvector_subset

#Transform the data 
Features_reduced = np.dot(eigenvector_subset.transpose(),Features.transpose()).transpose()
Features_reduced

LDA_df = pd.DataFrame(Features_reduced)
LDA_df

from sklearn.model_selection import train_test_split
from sklearn import metrics

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(LDA_df, Label, test_size=0.3, random_state=1)

"""Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
# Create Decision Tree classifer object
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred_train = clf.predict(X_train)

print("Training-set accuracy (in %):",metrics.accuracy_score(y_train, y_pred_train)*100)

# Create Decision Tree classifer object
clf = DecisionTreeClassifier(criterion="entropy", max_depth=8)

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print("Accuracy (in %):",metrics.accuracy_score(y_test, y_pred)*100)

"""Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB() 
gnb.fit(X_train, y_train) 

y_pred_train = gnb.predict(X_train)

print('Training-set accuracy (in %):', metrics.accuracy_score(y_train, y_pred_train)*100)

# making predictions on the testing set 
y_pred = gnb.predict(X_test)

print("Gaussian Naive Bayes model accuracy (in %):", metrics.accuracy_score(y_test, y_pred)*100)

"""Random Forest"""

# importing random forest classifier from assemble module
from sklearn.ensemble import RandomForestClassifier

# creating a RF classifier
rfcl = RandomForestClassifier(n_estimators = 100) 
 
# Training the model on the training dataset
rfcl.fit(X_train, y_train)

y_pred_train = rfcl.predict(X_train)

print('Training-set accuracy (in %):', metrics.accuracy_score(y_train, y_pred_train)*100)

# performing predictions on the test dataset
y_pred = rfcl.predict(X_test)
 
print('Training-set accuracy (in %):', metrics.accuracy_score(y_test, y_pred)*100)

"""SVM"""

#Import svm model
from sklearn import svm

#Create a svm Classifier
svmclf = svm.SVC(kernel='linear') # Linear Kernel

#Train the model using the training sets
svmclf.fit(X_train, y_train)

y_pred_train = svmclf.predict(X_train)

print('Training-set accuracy (in %):', metrics.accuracy_score(y_train, y_pred_train)*100)

#Predict the response for test dataset
y_pred = svmclf.predict(X_test)

# using metrics module for accuracy calculation
print("SVM model accuracy (in %): ", metrics.accuracy_score(y_test, y_pred)*100)

