# -*- coding: utf-8 -*-
"""Swetha_PCA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13oDra-Jv8wfeCa-L1_Lzpx69Dv5v5Cu3
"""

#Importing required libraries
import numpy as np
import pandas as pd

ctg_df=pd.read_csv("ctg_data1.csv")

ctg_df.head()

ctg_df.dtypes

#Checking for null values 
ctg_df.isna().sum()

ctg_df.dropna()

ctg_df.isna().sum()

Features=ctg_df.drop('NSP', axis=1)
Label=ctg_df['NSP']

"""PCA"""

# mean Centering the data  
Features_meaned = Features - np.mean(Features , axis = 0)
Features_meaned

# Calculate the co-variance matrix of the mean-centered data.
cov_matrix = np.cov(Features_meaned , rowvar = False)

#Calculating Eigenvalues and Eigenvectors of the covariance matrix
eigen_values , eigen_vectors = np.linalg.eigh(cov_matrix)

#sort the eigenvalues in descending order
sorted_index = np.argsort(eigen_values)[::-1]
 
sorted_eigenvalue = eigen_values[sorted_index]
#similarly sort the eigenvectors 
sorted_eigenvectors = eigen_vectors[:,sorted_index]
sorted_eigenvectors

# select the first n eigenvectors, n is desired dimension
# of our final reduced data.
 
n_components = 30 #you can select any number of components.
eigenvector_subset = sorted_eigenvectors[:,0:n_components]
eigenvector_subset

#Transform the data 
Features_reduced = np.dot(eigenvector_subset.transpose(),Features_meaned.transpose()).transpose()
Features_reduced

PCA_df = pd.DataFrame(Features_reduced)
PCA_df

from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics

# Split dataset into training set and test set
X_train, X_test, y_train, y_test = train_test_split(PCA_df, Label, test_size=0.3, random_state=1)

"""DECISION TREE"""

# Import Decision Tree Classifier
from sklearn.tree import DecisionTreeClassifier
# Create Decision Tree classifer object
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred_train = clf.predict(X_train)

print("Decision Tree Model Accuracy with training data (in %):",metrics.accuracy_score(y_train, y_pred_train)*100)

# Create Decision Tree classifer object
clf = DecisionTreeClassifier(criterion="entropy", max_depth=8)

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

print("Decision Tree model accuracy(in %):",metrics.accuracy_score(y_test, y_pred)*100)

"""Naive Bayes"""

from sklearn.naive_bayes import GaussianNB
gnb = GaussianNB() 
gnb.fit(X_train, y_train) 

y_pred_train = gnb.predict(X_train)

print('Gaussian Naive Bayes Training-set accuracy(in %):', metrics.accuracy_score(y_train, y_pred_train)*100)

# making predictions on the testing set 
y_pred = gnb.predict(X_test)

# comparing actual response values (y_test) with predicted response values 
print("Gaussian Naive Bayes model accuracy(in %):", metrics.accuracy_score(y_test, y_pred)*100)

"""Random Forest"""

# importing random forest classifier from assemble module
from sklearn.ensemble import RandomForestClassifier

# creating a RF classifier
rfclf = RandomForestClassifier(n_estimators = 100) 
 
# Training the model on the training dataset
rfclf.fit(X_train, y_train)
y_pred_train = rfclf.predict(X_train)

print('Training-set accuracy(in %):', metrics.accuracy_score(y_train, y_pred_train)*100)

# performing predictions on the test dataset
y_pred = rfclf.predict(X_test)

# using metrics module for accuracy calculation
print("Random Forest model accuracy(in %): ", metrics.accuracy_score(y_test, y_pred)*100)

"""SVM"""

#Import svm model
from sklearn import svm

#Create a svm Classifier
svmclf = svm.SVC(kernel='linear') # Linear Kernel

#Train the model using the training sets
svmclf.fit(X_train, y_train)

y_pred_train = svmclf.predict(X_train)

print('Training-set accuracy(in %):', metrics.accuracy_score(y_train, y_pred_train)*100)

#Predict the response for test dataset
y_pred = svmclf.predict(X_test)

# using metrics module for accuracy calculation
print("SVM model accuracy(in %): ", metrics.accuracy_score(y_test, y_pred)*100)

